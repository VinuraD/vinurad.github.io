---
layout: default
title: "Causality and ML-1"
permalink: /Causality-1/
---

# Causal Inference
This post mainly serves as a way for me to understand causality related concepts. The code related to the posts under causal ML would be placed in [this](https://github.com/VinuraD/CausalML.git) repository.

## Why RCT is not enough?
Randomized Control Treatments (RCT) can quantify cause-effect relationships. However, RCT can be costly or impractical in some scenarios due to being expensive, unethical or other reasons. For example, assigning random human subjects would not be ethical in medical experiments. A/B testing is a type of RCTs typically used for digital products or policy testing. However, it is insufficient to answer broad causality related questions such as interventions on any desired variable. In short, causal inference serves as the generalization of RCTs and A/B testing, being able to resolve many complex scenarios involving multitude of variables.
On a side note, the randomization in RCT, A/B removes backdoor paths (removes confounders). Let us take an example, where a treatment ($T$) is given to two groups of patients; one is sick and the other is not. If treatment assignment is not randomized, the doctor might naturally prefer the treatment to be given to sicker patients. However, the sicker patients also have the chance of getting worse. If the true cause-effect relationshop is required, then,

$$
Y(0) = outcome~if~the~treatment~not~given\\
Y(1) = outcome~if~the~treatment~given\\
Y=TY(1)+(1-T)Y(0)\\
T⊥(Y(0),Y(1));(if~randomized)\\
average~treatement~effect~(ATE)=E[Y(1)-Y(0)]\\
\\
E[Y|T=1]=E[1.Y(1)+0.Y(0)]=E[Y(1)]\\
E[Y|T=0]=E[0.Y(1)+1.Y(0)]=E[Y(0)]\\
\therefore E[Y|T=1]-E[Y|T=0]=E[Y(1)]-E[Y(0)]=E[Y(1)-Y(0)]\\
$$

This means that if we assume randomization is available, then RCT removes confounders and measure true cause-effect relationships.

## Treatment effect
In very simple terms, this measures the effect of a particular treatment, on the outcome variable. A main challenge for doing this is the unavailability of certain data (observations). For example, in a medical treatment scenario, one group would be assigned the treatment while another group would be not. In the group that was assigned the treatment, 'counterfactual' sceanarios of the subjects (what-if the treatment was not assigned to a person) are not available. Similarly, the other groups would not have counterfactual data - what if the treatment was applied to each person in that group. 
Meta-learners can estimate unobserved outcomes. For example, S-learner method can use any ML model to train on observed data and predict outcomes for unobserved instances. T-learner uses two separate models to train; one for the group with the treatment and one for the group without the treatment. 

## Conditional Ignorability
Methods in meta-learning rely on one crucial assumption - 'conditional ignorability'. In the example of treatment scenario above, only one confounder was present and other variables were absent. However, if other covariates are present ($X$), and we only want to measure the treatment effect of $T$ conditioned on $X$ (Conditioned ATE - CATE), we asssume that,

$$
Y(1),Y(0)~⊥~T|X\\
$$

Here, we assume that any confounder would be observed and correctly measured within $X$. But if there is an unmeasured confounder outside of $X$, this assumption breaks. This means that unwanted selection bias comes in that violates the randomness assumption.

## Instrumental variables (IV)
IVs are variables that helps to (partially) isolate the effect of unknown confounders in $X$. IVs should not have any dependencies with the unknown confounders and should not have a direct effect on the outcome. It should only affect the outcome through the treatment. By selecting the treatments that depends on IVs, we can find a 'Local ATE' that is limited by the IVs.

## Loss of timing
When measuring ATE, the outcome we get is an average of the treatment effect over a population. This removes an important piece of information - timing or directionality. 

